{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8a2301-3ab8-414a-87cd-28bcf7d0ae2d",
   "metadata": {},
   "source": [
    "# HELLO WELCOME TO THIS JOURNAL OF MINE IN THIS WHOLE JOURNEY. HOPE U ENJOY.\n",
    "### I  am sharing my experience below and how I approached it all in detail. Models I used...and thought of using and can not or problems I faced and how I overcame??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecade9cf-4b4e-4f84-b3a4-c5b62956545a",
   "metadata": {},
   "source": [
    "###### First of all, I am grateful for this opportunity. This is because I worked on ML based projects. But for the first time I worked with NLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b8ccd-791c-4c3f-bc40-7a7878981ff0",
   "metadata": {},
   "source": [
    "### What exactly is NLP ?? \n",
    "Processing (NLP) is a substream of artificial intelligence and computer science, the goal of which is to allow computers to recognize, translate, and generate human language in a way that is valuable and precise. It is the communication between computers and humans through natural language.\n",
    "It enables machines to read, understand, and interpret human language - in this case, speech and text. These agents do a variety of tasks, like parsing sentences, recognizing entities (like names and dates), and semantic relationships between words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4571c-9579-4e73-9a7f-84971cc78f32",
   "metadata": {},
   "source": [
    "### What is Sentiment Analysis\n",
    "* Sentiment Analysis is a subset of Natural Language Processing (NLP). It is to identify  and extract openion from reviews or feedbacks for either positive or negative.\n",
    "* Sentiment analyses are of different types-\n",
    "  * Emotion detection\n",
    "  * Aspect based Sentiment Analysis\n",
    "  * Multiple Sentiment Analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6f532-6f0d-49ff-b51d-27b2f7bf673b",
   "metadata": {},
   "source": [
    "In my asssinment i am asked to to do a fine-grain sentiment analysis, that is sentiment demo towards specific sub-themes/ aspects present in a review. \n",
    "So i used the 2nd Sentiment analyses which is Aspect based Sentiment Analysis. This includes NLP to pre-process the text, identify the aspects or problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89bb2d-57a7-47fe-adb0-d2715d2a140f",
   "metadata": {},
   "source": [
    "## Well then what is Aspect Based Sentiment Analyses approach? \n",
    "#### Lets dive into it a bit more!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8e8e7-560c-4fad-930e-6379d1b67299",
   "metadata": {},
   "source": [
    "It is breaking down the text into aspects(attributes or components of a product or services)and then allocates each one a sentiment level\n",
    "* Positive üòä\n",
    "* Neutral üòê\n",
    "* Negative üôÅ\n",
    "  text -> aspect -> allocate each one a sentiment level(Positive üòä, Neutral üòê, Negative üôÅ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf9346-feff-4374-9ca3-6abef0d52146",
   "metadata": {},
   "source": [
    "### 1. Understanding the Problem\n",
    "\n",
    "We need to:\n",
    "\n",
    "* first I need to identify subthemes within the provided texts.\n",
    "* then determine the sentiment associated with each subtheme of the texts.\n",
    "\n",
    "### 2. Approach\n",
    "\n",
    "* To solve this task, I used a combination of NLP techniques.\n",
    "* Text Preprocessing: 1stly we Clean and prepare the text for analysis.\n",
    "* Used Textblob: using this we can determine key subthemes or aspects in the text whether they are Positive üòä, Neutral üòê, Negative üôÅ.\n",
    "* Combining Results: Match sentiments with their respective aspects by comparing TextBlob sentiment with the provided sentiment.\n",
    "* Accuracy: To find  how accurate TextBlob Sentiment Analysis is.\n",
    "\n",
    "### 3. Tools and Libraries\n",
    "* I used NLTK for text preprocessing and basic NLP tasks.\n",
    "* I used Textblob for Aspect-based Sentiment Analysis (ABSA) models, BERT or VADER for sentiment analysis.(but i couldnt use them that a whole differnt story which i will share)\n",
    "* I used sklearn, matplotlib, seaborn and worldcloud for any machine learning algorithms and visual presentatioon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c84f5-f389-4b95-8321-c6fb92820e66",
   "metadata": {},
   "source": [
    "#### In the code part I have described every step. Still, let me provide a jest.\n",
    "\n",
    "* Load the CVS file to ensure the necessary libraries to read and manipulate the data. use panda library for that\n",
    "* Need understanding the cvs structure\n",
    "\n",
    "| review_id | review_text                                                                                                                                                                                                                                | aspect                                                                                                                                                                                                                                   | sentiment |\r\n",
    "|---|---|---|---|\r\n",
    "| 1        | One tyre went missing...                                                                                                                                                                                                                           | incorrect tyres sent                                                                                                                                                                                                                  | negative  |\r\n",
    "| 2        | The way garage dealt with it was fantastic.                                                                                                                                                                                                              | garage service                                                                                                                                                                                                                           | positive  |\r\n",
    "| ...      | ...                                                                                                                                                                                                                                                                  | ...                                                                                                                                                                                                                                     | ...       |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52986c2b-0e81-497b-b218-b964f9dfe960",
   "metadata": {},
   "source": [
    "### Steps to Process the DataFrame\n",
    "* Rename the review text column: We rename it to enhance the readability and clarity to make it more descriptive. I used review_texts in the code.\n",
    "\n",
    "* Melt the DataFrame: Melting is a very important step. It transforms a DataFrame with stacked columns into a single column containing variable names and a corresponding value column. Melting creates a single row for each review-aspect combination, making it easier to analyze for aspect-based analysis.\n",
    "\n",
    "* Drop rows with NaN values: Although it's optional yet I prefer to deal with missing values. Missing values (NaN) can lead to errors or inaccurate analysis. These values are not meaningful for your analysis, we can drop them or fill them with appropriate strategies as per our convinience and dataset. But not dealing with them lead to low accuracy. Here mine were not relevant so i dropped them. \n",
    "\n",
    "* Split the aspect_sentiment into aspect and sentiment: Spliting is for independent analysis of aspects and sentiments. to go deep down and analyse in a more granular way. My data sets had combined column for aspect and sentiment (e.g aspect_sentiment' into 'aspect' and 'sentiment'). I splitted this to analyze aspects and sentiments independently.\n",
    "   | aspect_sentiment                     | aspect                   | sentiment |\r\n",
    "|---|---|---|\r\n",
    "| garage service positive                | garage service         | positive  |\n",
    "\r\n",
    "\n",
    "* Group by review to combine aspects and sentiments for each rev: An essential step is understanding the overall sentiment and patterns within each review for further analysis. By grouping I aggregate the aspects and sentiments associated with each review. This helped me identify recurring themes or patterns within data feedback.iew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2cc890-9b4e-49a2-bef4-e1e68df687d6",
   "metadata": {},
   "source": [
    "## And the after melting DataFrame somewhat looks like this:\n",
    "\n",
    "| review_text                                                         | aspect_column               | aspect_sentiment            | aspect              | sentiment |\r\n",
    "|---------------------------------------------------------------------|-----------------------------|-----------------------------|---------------------|-----------|\r\n",
    "| Easy Tyre Selection Process, Competitive Pricing                    | garage service positive     | garage service positive     | garage service      | positive  |\r\n",
    "| Very easy to use and good value for money.                          | garage service positive     | value for money positive    | value for money     | positive  |\r\n",
    "| Really easy and convenient to arrange                               | garage service positive     | ease of booking positive    | ease of booking     | positive  |\r\n",
    "| It was so easy to select tyre sizes and arrange fitting.            | garage service positive     | location positive           | location            | positive  |\r\n",
    "| Service was excellent. Only slight downside was length of fitting   | garage service positive     | length of fitting positive  | length of fitting   | positive  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193ca0f-ecb7-44fa-9a5e-36a957d6021e",
   "metadata": {},
   "source": [
    "## And the after grouping DataFrame somewhat looks like this:\n",
    "\n",
    "| Review Text                                                | Aspect Column                                      | Aspect Sentiment                                      | Aspect                                 | Sentiment                       |\r\n",
    "|------------------------------------------------------------|----------------------------------------------------|-------------------------------------------------------|---------------------------------------|---------------------------------|\r\n",
    "| - Easily understood website - simple procedure...          | [garage service positive, ease of booking positive, ...] | [garage service positive, location positive, ...]    | [garage service, location, ...]       | [positive, positive, ...]       |\r\n",
    "| 1 of the tire fitted has a slow puncture.                  | [garage service positive]                          | [damage negative]                                     | [damage]                              | [negative]                      |\r\n",
    "| 1 of the tyres was an old tyre. I have bought ...          | [garage service positive, ease of booking positive, ...] | [tyre agedot code positive, call wait time negative, ...] | [tyre agedot code, call wait time, ...] | [positive, negative, ...]       |\r\n",
    "| 1 the service was good. 2 the price I'd good               |                                                    |                                                       |                                       |                                 |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8c730-2600-4ce1-b72f-7f60dfd871e5",
   "metadata": {},
   "source": [
    "## Now the most anticipated question....why textblob and not RNN, GNU, LSTM or BERT?? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b6034-79ba-4a42-b335-a4841046baea",
   "metadata": {},
   "source": [
    "Well honestly my area of expertise was linear and logistic regression, and classification models of Machine learning and training those models but sentiment analysis is mostly done with NLP, an overlap of ML and deep learning. So it was kind of new for me. The whole concept as well as how to approach the models. What would be the suitable model? And within 2 days I had to understand NLP which I other than the full form was not exposed to much. I took shorter courses online and short videos to learn about NLP and speech processing, types of sentiment analysis, sources of reviews and applications, neural networks, models and how to approach. But all purely theory and was able to code little by little.\n",
    "\n",
    "Till I reached for the models the coding part was quite smooth and easy. just follow the methods and basic pandas and loading of CVS, melting data, and grouping. the moment I was learning about the RNN training model which is also known as the Recurrent Neural model used most famously for sentiment. well before that I tried BERT as BERT is a transformer-based model and they are best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9af0d0-1dd9-4f03-a114-b69ff1bf0d3d",
   "metadata": {},
   "source": [
    "#### WHY BERT??\n",
    "\n",
    "* they are self-attention mechanisms, so it allows them to focus on various different parts of the input sequence for their outputs respectively.\n",
    "* Thereby capturing long-range dependencies effectively.\n",
    "* They are also Bidirectional Encoder Representations from transformers and can be fine-tuned for specific tasks like sentiment analysis with smaller data and the provided data was also a small amount of task-specific dataset with only a RangeIndex of 10131 entries, (0 to 10130) and 15 objects as data columns with a memory usage of 1.2+ MB. apparently is very small.\n",
    "* BERT is also very flexible have a very powerful architecture capturing complex patterns quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e82bc-f626-468e-b04b-270fb9e6d06a",
   "metadata": {},
   "source": [
    "### Now Why not??\n",
    "* Well although I thought it was the apt model yet I faced various issues. \n",
    "* Loads of errors as TensorFlow was not working version was not matching.\n",
    "* I changed the whole environment... conda activate a new project base and re coded everything from scratch while installing old packages anew.\n",
    "* But the transformer won't work. Transformer and TensorFlow were not working.\n",
    "*  I reinstalled Jupyter Notebook, changed versions, and did my very best but it was becoming not only hard and complicated...it was also creating other issues in my laptop which is why I had to drop such a beautiful option which I will absolutely explore more later and figure out and address every issue but certainly not for 2 days task time where I have to rewrite everything installing and uninstalling twice or thrice.\n",
    "*  Moreover my laptop became slow too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca58ac-7f7c-484d-b6ae-0cc810802852",
   "metadata": {},
   "source": [
    "### Then what??\n",
    "**Of course...RNN...the next best out there!!** but now Tensorflow was creating new issues so I had to drop the whole idea of using Tensorflow. As the libraries of TensorFlow were not working and constantly creating unsolvable issues and I had no one to guide me as I self-taught everything.\n",
    "\n",
    "At that time I thought of dropping the whole idea of proceeding further and informing for withdrawal. my brain stopped working completely exhausted. No motivation at all and slept as was not well at the same time. When I woke up after 3 to 4 hours of sleep and looked at the closed laptop...suddenly a force made me stubborn and turn my laptop up to clear tons of junk files and again sit to teach myself a way out and that I won't give up. \n",
    "\n",
    "### (A Small inspiring sad story about me..you can skip it if you want. But success always makes a human mad happy and overshare üòÖ to motivate)\n",
    "So what happened was in one of the recent projects in my college under IoT we were working on a Smart dustbin and thought about making aurdino board and circuits and all completely physical and coding to automate. But our teachers had other plans and wanted a digital version i.e. a design not the physical one at this moment. So brain-wreaking and meeting we found they wanted it in Blender, a software known to none ...few knew and said it was impossible... hard software interface and within a week is impossible. And sir gave us 4 days. 1 or 2 days passed nobody was trying or everyone was like let's not do it and say sir it's hard. So I thought how hard can it be?? **A challenge!** that things that they say are hard I will make it easy and be expert. I sat one day at 11.30 pm after all my work was done to explore...I didn't sleep a whole day and explored...learned new features applied and created a masterpiece till 12pm in the afternoon...using more new technologies and software..learning and combining...and creating. people were speechless and in awe and motivated...and some were like **\"Yours is not a gaming laptop it's a very average laptop provided to all from college ... how come it didn't burn yet rendered such beautiful 3d pics which was impossible for us...how come you did it?\"**\n",
    "\n",
    "##### Now why a masterpiece and sad story....\n",
    "Masterpiece because when my teacher saw that he immediately asked for uk patent application along with an application fee from me but I had no plan of doing that and was out of budget. so without telling me anything and taking advantage of exams, he filed for the patent...with only the pics and he along with another student ...completely unrelated applied and got the patent along with an international certificate. Not only that he showed it to the HOD and principal and they said if students can make such high-profile projects they will start funding for foreign applications and project development...and very soon start a physical batch of that design. my design got sold out college funded and so many thing happened yet it was a sad memory for me...but ok at least I completed my challenge.\n",
    "\n",
    "**\" When you want something all the universe conspires in helping you to achieve it. \"**-Paulo Coelho from the book The Alchemist \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b4c86-61d2-402c-98cc-8a8276613789",
   "metadata": {},
   "source": [
    "## So never stop ..like i didnt...\n",
    "* I surfed the net\n",
    "* read numerous Stackoverflow, Geeks for GeeKs applies logic and failed\n",
    "* read from Kaggle\n",
    "* tried various YouTube sources and everyone's was different...and noted, typed, and tried and brain storm a lot...\n",
    "* for the next several hours i hated the red warning and errors did so many research only to find that RNN and BERT will fail and then from soume source in Google I found one more very simplified version of the model...readable easy and suitable for my environment.\n",
    "* that was **Textblob**\n",
    "\n",
    "Apparently, Textblob is one of the most popular library for NLP in Python that to for Sentiment analysis in particular. Because of its ease of use, user-friendly for both beginner and advanced users, (very very true...believe me!).\n",
    "It's pre-trained in speech-tagging and sentiment analysis built on NLTP with a wide range strong foundation of NLP functionalities. It provided polarity and subjectivity to provided text by extraction and, translation and language detection...a comprehensive text analysis. I removed Stopwords and lemmatized words to normalize the provided texts. \n",
    "\n",
    "Moreover, my system was well suited ...although there were minute errors by using debugging methods of printing and checking I figured out things quite efficiently and easily. great to learn such a beautiful and wonderful model.\n",
    "TextBlob also has a strong community and good documentation helping me a lot to learn to use the library effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7da551-6c4a-4f7a-aa2f-adcee1e49977",
   "metadata": {},
   "source": [
    "### Then the accuracy was a moment of joy for me\n",
    "An accuracy of 83.45 for me who learned everything anew was really a success for me. I will try to improve the accuracy with time.\n",
    "and **what's an analysis without visual presentation?** So I incorporated various data visualization techniques like comparisonplot, subplot,heatmap boxplot, countplot, piechart to give it a bit of colour and make it interesting, easy to understand visually and cool. For that I installed and used WordCloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce17887-a756-42b5-b220-cbe8244225e9",
   "metadata": {},
   "source": [
    "## Looks like i came to the end of the documentation also like my journal.\n",
    "\n",
    "### A Short Summary--->\n",
    "\n",
    "**Approach:**\n",
    "* Loading and preprocessing the CSV data to structure it for analysis.\n",
    "\n",
    "* Using the structured data to identify aspects and sentiments in new reviews.\n",
    "\n",
    "**Motivation:** \n",
    "* The trial and error method taught me a lot. Next time I can consider a variety of models for my next project\n",
    "\n",
    "*  I didn't give up and explored 2 to 3 models learned faced issues and still kept on learning and improving the accuracy and reliability of the sentiment analysis.\n",
    "\n",
    "**Shortcomings:** \n",
    "* Sentiment analysis can sometimes misinterpret sentiments without context.\n",
    "\n",
    "* As my provided data is smaller in size there is a high chance so misinterpretation and textblob needs a wide range to detect and analyze so accuracy is in 80's not 90's or 100 percent\n",
    "  \n",
    "**Improvements** \n",
    "* Use more advanced aspect extraction methods like BENT or machine learning-based NER, dependancy parsing or RNN, GNU.\n",
    "\n",
    "* I could have improved sentiment analysis by fine-tuning models on domain-specific data.\n",
    "\n",
    "**Result**\n",
    "* Some cool data visualization for easy understanding of the code and dataset provided.\n",
    "\n",
    "* An accuracy of 83.14 percent from 0 to 20 to 50 to finally 83.14 was hard yet interesting.\n",
    "\n",
    "* Learned a few new models and complete new topics theoretically and coded then dauntingly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be683127-3c57-4d53-bbb3-4dcfc969f53e",
   "metadata": {},
   "source": [
    "## Finally I would love to show my gratitude to team Oriserve for again giving me the chance I know it's a bit late. \n",
    "## Thank you so much for this opportunity. \n",
    "## I wasn't well for 1 week but that too with sour mood but my mood got lifted with this journey of 2 days.\n",
    "## I enjoyed every step of excitement to learning to failure to success to finally ending this project.\n",
    "## Although I don't know if I would be chosen or not to work with the team....hope that I can make it to the team...only positive thoughts and dreams do not make humans soulless. Anyways, thank you team oriserver and you guys rock!!\n",
    "## ü•∞‚ù§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090d5a0-2b8f-4c42-be80-a2a8c28dbe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
